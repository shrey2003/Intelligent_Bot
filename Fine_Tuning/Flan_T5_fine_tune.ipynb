{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9054317,"sourceType":"datasetVersion","datasetId":5459531}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-29T12:12:39.689105Z","iopub.execute_input":"2024-07-29T12:12:39.689458Z","iopub.status.idle":"2024-07-29T12:12:40.107780Z","shell.execute_reply.started":"2024-07-29T12:12:39.689425Z","shell.execute_reply":"2024-07-29T12:12:40.106799Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/quora-qsans/quora_dataset_test.csv\n/kaggle/input/quora-qsans/quora_dataset_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers[torch] tokenizers datasets evaluate rouge_score sentencepiece pandas wandb\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:12:40.109725Z","iopub.execute_input":"2024-07-29T12:12:40.110174Z","iopub.status.idle":"2024-07-29T12:12:57.298943Z","shell.execute_reply.started":"2024-07-29T12:12:40.110139Z","shell.execute_reply":"2024-07-29T12:12:57.297934Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.19.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.4)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.32.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.8.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=1e1e49a037f91fbb7b4e29e114d82d7b739d1751d05937ed2f24b54b216d726b\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.2 rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\n# df = pd.read_csv('/kaggle/input/preprocessed-quora-dataset/quora_dataset_preprocessed.csv')\n# train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df=pd.read_csv('/kaggle/input/quora-qsans/quora_dataset_train.csv')\ntest_df=pd.read_csv('/kaggle/input/quora-qsans/quora_dataset_test.csv')\ntest_df=test_df[:1000]\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:12:57.300544Z","iopub.execute_input":"2024-07-29T12:12:57.301425Z","iopub.status.idle":"2024-07-29T12:13:00.511015Z","shell.execute_reply.started":"2024-07-29T12:12:57.301387Z","shell.execute_reply":"2024-07-29T12:13:00.509950Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.init(\"Flan-T5-FineTune\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:13:00.512211Z","iopub.execute_input":"2024-07-29T12:13:00.512612Z","iopub.status.idle":"2024-07-29T12:14:19.659556Z","shell.execute_reply.started":"2024-07-29T12:13:00.512554Z","shell.execute_reply":"2024-07-29T12:14:19.658580Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240729_121402-17finbq4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amazeml/uncategorized/runs/17finbq4' target=\"_blank\">celestial-night-15</a></strong> to <a href='https://wandb.ai/amazeml/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amazeml/uncategorized' target=\"_blank\">https://wandb.ai/amazeml/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amazeml/uncategorized/runs/17finbq4' target=\"_blank\">https://wandb.ai/amazeml/uncategorized/runs/17finbq4</a>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/amazeml/uncategorized/runs/17finbq4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x78ac4dd2d180>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:14:19.662714Z","iopub.execute_input":"2024-07-29T12:14:19.663072Z","iopub.status.idle":"2024-07-29T12:15:02.856313Z","shell.execute_reply.started":"2024-07-29T12:14:19.663028Z","shell.execute_reply":"2024-07-29T12:15:02.855330Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-07-29 12:14:23.622437: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-29 12:14:23.622547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-29 12:14:23.720862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55658e81d90140ddba4d7e5c26a23348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"747c631660d048a89b310f318938a47b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a6fb061b73044478392aa07e6b8a9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604640809e7b401cb572205e5feb03b3"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c86587178a6475184e9789a36d9adca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ded575e109b41439ba592d75e0e568a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bc4a2aff8a493289db47c34c7ee4dc"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [\"answer the question: \" + str(doc) for doc in examples[\"question\"]]\n    model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n    labels = tokenizer(text_target=[str(ans) for ans in examples[\"answer\"]], max_length=512, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:02.859585Z","iopub.execute_input":"2024-07-29T12:15:02.860806Z","iopub.status.idle":"2024-07-29T12:15:51.094224Z","shell.execute_reply.started":"2024-07-29T12:15:02.860777Z","shell.execute_reply":"2024-07-29T12:15:51.093113Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/44145 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57aed377b4724487a13555ae863e12ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a00d8c902a4865a00c510af49fddd0"}},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\nimport nltk\n\nnltk.download(\"punkt\", quiet=True)\nrouge = evaluate.load('rouge')\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n    \n    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n#     bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n\n    result = {\n        \"rouge1\": rouge_result['rouge1']*100,\n        \"rouge2\": rouge_result['rouge2']*100,\n        \"rougeL\": rouge_result['rougeL']*100\n    }\n        # Log metrics to wandb\n    wandb.log(result)\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:51.095653Z","iopub.execute_input":"2024-07-29T12:15:51.096044Z","iopub.status.idle":"2024-07-29T12:15:53.896007Z","shell.execute_reply.started":"2024-07-29T12:15:51.096001Z","shell.execute_reply":"2024-07-29T12:15:53.895006Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6347b6a2099481da21ef2cb1e171512"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainerCallback\n\nclass EarlyStoppingCallback(TrainerCallback):\n    def __init__(self, early_stopping_patience=3):\n        self.early_stopping_patience = early_stopping_patience\n        self.best_metric = None\n        self.counter = 0\n\n    def on_evaluate(self, args, state, control, **kwargs):\n        logs = kwargs['metrics']\n        current_metric = logs.get('eval_rougeL')\n\n        if self.best_metric is None or current_metric > self.best_metric:\n            self.best_metric = current_metric\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        if self.counter >= self.early_stopping_patience:\n            control.should_training_stop = True\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:53.897282Z","iopub.execute_input":"2024-07-29T12:15:53.898348Z","iopub.status.idle":"2024-07-29T12:15:53.906284Z","shell.execute_reply.started":"2024-07-29T12:15:53.898319Z","shell.execute_reply":"2024-07-29T12:15:53.905360Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\nlogin(token = hf_token)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:53.907823Z","iopub.execute_input":"2024-07-29T12:15:53.908127Z","iopub.status.idle":"2024-07-29T12:15:54.430505Z","shell.execute_reply.started":"2024-07-29T12:15:53.908103Z","shell.execute_reply":"2024-07-29T12:15:54.429359Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Save the DataFrame to a CSV file\n# train_df.to_csv('/kaggle/working/quora_dataset_train.csv', index=False)\n# # Save the DataFrame to a CSV file\n# test_df.to_csv('/kaggle/working/quora_dataset_test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:54.431766Z","iopub.execute_input":"2024-07-29T12:15:54.432048Z","iopub.status.idle":"2024-07-29T12:15:54.437151Z","shell.execute_reply.started":"2024-07-29T12:15:54.432017Z","shell.execute_reply":"2024-07-29T12:15:54.435818Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"steps\",\n    eval_steps=5000,\n    save_steps=5000,\n    save_strategy=\"steps\",\n    logging_strategy=\"steps\",\n    logging_steps=250,\n    learning_rate=3e-4,\n    per_device_train_batch_size=6,\n    per_device_eval_batch_size=6,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    report_to=\"wandb\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rougeL\",\n    push_to_hub=True,\n    generation_max_length=256\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3))\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:15:54.438524Z","iopub.execute_input":"2024-07-29T12:15:54.438832Z","iopub.status.idle":"2024-07-29T15:39:43.951330Z","shell.execute_reply.started":"2024-07-29T12:15:54.438801Z","shell.execute_reply":"2024-07-29T15:39:43.950289Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22074' max='22074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22074/22074 3:23:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5000</td>\n      <td>4.682400</td>\n      <td>4.389001</td>\n      <td>4.006344</td>\n      <td>0.768673</td>\n      <td>3.723546</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>4.396900</td>\n      <td>4.284409</td>\n      <td>4.087990</td>\n      <td>0.829393</td>\n      <td>3.806167</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>4.255000</td>\n      <td>4.227406</td>\n      <td>4.890976</td>\n      <td>0.989087</td>\n      <td>4.443849</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>4.189600</td>\n      <td>4.198068</td>\n      <td>5.174746</td>\n      <td>1.069558</td>\n      <td>4.701640</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=22074, training_loss=4.442926856004059, metrics={'train_runtime': 12182.4205, 'train_samples_per_second': 10.871, 'train_steps_per_second': 1.812, 'total_flos': 5115951909559296.0, 'train_loss': 4.442926856004059, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model locally\nmodel.save_pretrained(\"/kaggle/working/saved_model\")\ntokenizer.save_pretrained(\"/kaggle/working/saved_model\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T15:39:43.952824Z","iopub.execute_input":"2024-07-29T15:39:43.953151Z","iopub.status.idle":"2024-07-29T15:39:45.466110Z","shell.execute_reply.started":"2024-07-29T15:39:43.953118Z","shell.execute_reply":"2024-07-29T15:39:45.465005Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/saved_model/tokenizer_config.json',\n '/kaggle/working/saved_model/special_tokens_map.json',\n '/kaggle/working/saved_model/spiece.model',\n '/kaggle/working/saved_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T15:39:45.468226Z","iopub.execute_input":"2024-07-29T15:39:45.468513Z","iopub.status.idle":"2024-07-29T15:39:45.473391Z","shell.execute_reply.started":"2024-07-29T15:39:45.468487Z","shell.execute_reply":"2024-07-29T15:39:45.472285Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}